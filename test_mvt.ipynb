{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba16c0fc-354c-4ff7-a4d2-bcf3df3b37ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.0.7) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from helpers import plotframes, plotframes_tensorboard\n",
    "from mvt import MaskedVideoTransformer\n",
    "from gameds import GameDS\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import random\n",
    "import argparse\n",
    "from dual_logger import DualLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad68d4f-5357-4d7c-a5af-d076f9d78a69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run started\n",
      "Dataloader length 298\n",
      "SHAPES torch.Size([24, 2, 1, 128, 128]) torch.Size([24, 2, 1, 128, 128])\n",
      "SHAPES torch.Size([24, 2, 1, 128, 128]) torch.Size([24, 2, 1, 128, 128])\n",
      "SHAPES torch.Size([24, 2, 1, 128, 128]) torch.Size([24, 2, 1, 128, 128])\n",
      "SHAPES torch.Size([24, 2, 1, 128, 128]) torch.Size([24, 2, 1, 128, 128])\n",
      "SHAPES torch.Size([24, 2, 1, 128, 128]) torch.Size([24, 2, 1, 128, 128])\n",
      "SHAPES torch.Size([24, 2, 1, 128, 128]) torch.Size([24, 2, 1, 128, 128])\n",
      "SHAPES torch.Size([24, 2, 1, 128, 128]) torch.Size([24, 2, 1, 128, 128])\n",
      "SHAPES torch.Size([24, 2, 1, 128, 128]) torch.Size([24, 2, 1, 128, 128])\n",
      "SHAPES torch.Size([24, 2, 1, 128, 128]) torch.Size([24, 2, 1, 128, 128])\n",
      "SHAPES torch.Size([24, 2, 1, 128, 128]) torch.Size([24, 2, 1, 128, 128])\n",
      "SHAPES torch.Size([24, 2, 1, 128, 128]) torch.Size([24, 2, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.device = \"cpu\"\n",
    "        self.lr = 0.01\n",
    "        self.n_frames = 2\n",
    "\n",
    "args = Args()\n",
    "\n",
    "writer = DualLogger(log_dir=f'./logs3/{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}_{str(uuid.uuid4())}', project_name='my_project')\n",
    "\n",
    "args_str = \"\\n\".join(f\"{k}: {v}\" for k, v in vars(args).items())\n",
    "writer.tensorboard_writer.add_text('Hyperparameters', args_str, 0)\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model = MaskedVideoTransformer(NUM_FRAMES=args.n_frames, COLOR_CHANNELS=1, D_DIM=736, PATCH_SIZE=32)\n",
    "model.to(args.device);\n",
    "\n",
    "import wandb\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "print(\"run started\")\n",
    "\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from helads import HelaData\n",
    "\n",
    "hela_train = HelaData(\"/home/constantin/Documents/celltracking/HeLa_dataset/train\", sequence_length=args.n_frames)\n",
    "hela_val = HelaData(\"/home/constantin/Documents/celltracking/HeLa_dataset/train\", sequence_length=args.n_frames)\n",
    "train_dataloader = DataLoader(hela_train, batch_size=24, shuffle=True, prefetch_factor=None, num_workers=0)\n",
    "val_dataloader = DataLoader(hela_val, batch_size=24, shuffle=True, prefetch_factor=None, num_workers=0)\n",
    "\n",
    "print(\"Dataloader length\", len(train_dataloader))\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optim = torch.optim.Adam(params=model.parameters(), lr=args.lr)\n",
    "\n",
    "step = 0\n",
    "optim.zero_grad()\n",
    "for _ in range(1000000):\n",
    "    torch.save(model.state_dict(), \"model.pt\")\n",
    "    for i_step, (X, _) in enumerate(train_dataloader):\n",
    "\n",
    "        X = X.to(args.device)\n",
    "        \n",
    "        \n",
    "        X_pred, (X_masked, ) = model(X)\n",
    "        \n",
    "        print(\"SHAPES\", X_pred.shape, X_masked.shape)\n",
    "\n",
    "        loss = criterion(X_pred, X)\n",
    "    \n",
    "        loss.backward()\n",
    "        if step%20 == 19 or True:\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    " \n",
    "        writer.add_scalar('Training loss', loss.item(), step)\n",
    "    \n",
    "        if step%20 == 10:\n",
    "            image_tensor = plotframes_tensorboard(X_masked, f\"Train: Mask {step}\")\n",
    "            writer.add_image('Train: Mask', image_tensor, step)\n",
    "\n",
    "            image_tensor = plotframes_tensorboard(X_pred, f\"Train: Prediction {step}\")\n",
    "            writer.add_image('Train: Prediction', image_tensor, step)\n",
    "\n",
    "            image_tensor = plotframes_tensorboard(X, f\"Train: Original {step}\")\n",
    "            writer.add_image('Train: Original', image_tensor, step)\n",
    "\n",
    "            image_tensor = plotframes_tensorboard([X, X_pred, X_masked], f\"Train: Combined {step}\")\n",
    "            writer.add_image('Train: Combined', image_tensor, step)\n",
    "    \n",
    "            # evaluation dataset\n",
    "            X_eval, _ = random.choice(hela_val)\n",
    "            X_eval = X_eval[None].to(args.device)\n",
    "            X_eval_pred, (X_eval_pred_masked, ) = model(X_eval)\n",
    "            \n",
    "            print(\"before eval\", X_eval.shape, X_eval_pred_masked.shape, X_eval_pred.shape)\n",
    "            loss = criterion(X_eval_pred, X_eval[0])\n",
    "            writer.add_scalar('Validation loss', loss.item(), step)\n",
    "    \n",
    "            image_tensor = plotframes_tensorboard(X_eval_pred_masked, f\"Val: Mask {step}\")\n",
    "            writer.add_image('Val: Mask', image_tensor, step)\n",
    "            \n",
    "            image_tensor = plotframes_tensorboard(X_eval_pred, f\"Val: Prediction {step}\")\n",
    "            writer.add_image('Val: Prediction', image_tensor, step)\n",
    "        \n",
    "            image_tensor = plotframes_tensorboard(X_eval, f\"Val: Original {step}\")\n",
    "            writer.add_image('Val: Original', image_tensor, step)\n",
    "\n",
    "            image_tensor = plotframes_tensorboard([X_eval, X_eval_pred, X_eval_pred_masked], f\"Val: Combined {step}\")\n",
    "            writer.add_image('Eval: Combined', image_tensor, step)\n",
    "\n",
    "            del X_eval_pred\n",
    "            del X_eval_pred_masked\n",
    "\n",
    "\n",
    "        del X_pred\n",
    "        del X_masked\n",
    "        step += 1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47f3fc6-90c7-4071-be6e-13cb0d835e11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
